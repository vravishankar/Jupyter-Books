{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Data\n",
    "\n",
    "As pandas is built on Python, any means available in Python can be used to retrieve data from outside source. This really makes the possibility of the data that can be accessed unlimited including text files, excel spreadsheets, web sites and services, databases and cloud based services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Python notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas and numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set some pandas options for controlling output\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns',10)\n",
    "pd.set_option('display.max_rows',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV & Text/Tabular Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Volume,Adj Close\r\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n",
      "2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\r\n",
      "2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\r\n"
     ]
    }
   ],
   "source": [
    "# view the first five lines of data/msft.csv\n",
    "! head -n 5 ../../data/msft.csv # OS/Linux\n",
    "# !type ..\\..\\data\\msft.csv     # on windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a CSV file into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in msft.csv into a DataFrame\n",
    "msft = pd.read_csv(\"../../data/msft.csv\")\n",
    "msft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Open   High    Low  Close   Volume  Adj Close\n",
       "Date                                                      \n",
       "2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specifying the index column\n",
    "msft = pd.read_csv(\"../../data/msft.csv\", index_col=0)\n",
    "msft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data field is now the index however because of this it is also not a column data. If you want to use the date as a column, you will need to create a new column and assign the index labels to that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         float64\n",
       "High         float64\n",
       "Low          float64\n",
       "Close        float64\n",
       "Volume         int64\n",
       "Adj Close    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the types of the columns in the DataFrame\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          object\n",
       "Open         float64\n",
       "High         float64\n",
       "Low          float64\n",
       "Close        float64\n",
       "Volume       float64\n",
       "Adj Close    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to force type of columns, use the dtypes parameter\n",
    "# following forces the column to be float64\n",
    "msft = pd.read_csv(\"../../data/msft.csv\", dtype={'Volume': np.float64})\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             open   high    low  close   volume  adjclose\n",
       "2014-07-21  83.46  83.53  81.81  81.93  2359300     81.93\n",
       "2014-07-18  83.30  83.40  82.52  83.35  4020800     83.35\n",
       "2014-07-17  84.35  84.63  83.33  83.63  1974000     83.63\n",
       "2014-07-16  83.77  84.91  83.66  84.91  1755600     84.91\n",
       "2014-07-15  84.30  84.38  83.20  83.58  1874700     83.58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify a new set of names for the columns\n",
    "# all lower case, remove space in Adj Close\n",
    "# also, header = 0 skips the header row\n",
    "df = pd.read_csv(\"../../data/msft.csv\",header=0,names=['open','high','low','close','volume','adjclose'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Close\n",
       "Date             \n",
       "2014-07-21  81.93\n",
       "2014-07-18  83.35\n",
       "2014-07-17  83.63\n",
       "2014-07-16  84.91\n",
       "2014-07-15  83.58"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data only in the Date and close columns,\n",
    "# use Date as the inde\n",
    "df2 = pd.read_csv(\"../../data/msft.csv\",usecols=['Date','Close'],index_col=['Date'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save df2 to a new csv file\n",
    "# also specify naming the index as date\n",
    "df2.to_csv(\"../../data/msft_modified.csv\",index_label='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was necessary to tell the method that the index label should be saved with a column name of date using index_label=date. Otherwise, the index does not have a name added to the first row of the file, which makes it difficult to read back properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date,Close\r\n",
      "2014-07-21,81.93\r\n",
      "2014-07-18,83.35\r\n",
      "2014-07-17,83.63\r\n",
      "2014-07-16,84.91\r\n",
      "2014-07-15,83.58\r\n",
      "2014-07-14,84.4\r\n",
      "2014-07-11,83.35\r\n",
      "2014-07-10,83.42\r\n",
      "2014-07-09,85.5\r\n"
     ]
    }
   ],
   "source": [
    "# view the start of the file just saved\n",
    "!head ../../data/msft_modified.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Field-Delimited Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use read_table with sep=',' to read a csv\n",
    "df=pd.read_table(\"../../data/msft.csv\",sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Date|Open|High|Low|Close|Volume|Adj Close\r\n",
      "0|2014-07-21|83.46|83.53|81.81|81.93|2359300|81.93\r\n",
      "1|2014-07-18|83.3|83.4|82.52|83.35|4020800|83.35\r\n",
      "2|2014-07-17|84.35|84.63|83.33|83.63|1974000|83.63\r\n",
      "3|2014-07-16|83.77|84.91|83.66|84.91|1755600|84.91\r\n"
     ]
    }
   ],
   "source": [
    "# save as pipe delimited\n",
    "df.to_csv(\"../../data/msft_piped.txt\",sep='|')\n",
    "# check if it worked\n",
    "!head -n 5 ../../data/msft_piped.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling noise rows in a dataset\n",
    "\n",
    "Sometimes, data in a field-delimited file may contain erroneous headers and footers. Examples can be company information at the top, such as invoice number, addresses and summary footers. Sometimes data is stored on ever other line. These situations will cause error when pandas tries to open files. To handle these scenarios some useful parameters can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is fun because the data does not start on the first line\r\n",
      "Date,Open,High,Low,Close,Volume,Adj Close\r\n",
      "\r\n",
      "And there is space between the header row and data\r\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n",
      "2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\r\n",
      "2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\r\n",
      "2014-07-15,84.30,84.38,83.20,83.58,1874700,83.58\r\n",
      "2014-07-14,83.66,84.64,83.11,84.40,1432100,84.40\r\n"
     ]
    }
   ],
   "source": [
    "# messy file\n",
    "!head ../../data/msft2.csv  # Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58\n",
       "5  2014-07-14  83.66  84.64  83.11  84.40  1432100      84.40\n",
       "6  2014-07-11  83.55  83.98  82.85  83.35  2001400      83.35\n",
       "7  2014-07-10  85.20  85.57  83.36  83.42  2713300      83.42\n",
       "8  2014-07-09  84.83  85.79  84.76  85.50  1540700      85.50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read, but skip rows 0,2 and 3\n",
    "df = pd.read_csv(\"../../data/msft2.csv\",skiprows=[0,2,3])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common situation is where a file has content at the end of the file which should be ignored to prevent an error, such as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Volume,Adj Close\r\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n",
      "\r\n",
      "Uh oh, there is stuff at the end."
     ]
    }
   ],
   "source": [
    "# another messy  file with mess at the end\n",
    "!cat ../../data/msft_with_footer.csv # osx / Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip only two lines at the end\n",
    "# engine parameter to force python implementation rather than default c implementation\n",
    "df = pd.read_csv(\"../../data/msft_with_footer.csv\",skipfooter=2,engine='python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only process the first three rows\n",
    "pd.read_csv(\"../../data/msft.csv\",nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             open   high    low  close      vol  adjclose\n",
       "2014-03-03  80.35  81.31  79.91  79.97  5004100     77.40\n",
       "2014-02-28  82.40  83.42  82.17  83.42  2853200     80.74\n",
       "2014-02-27  84.06  84.63  81.63  82.00  3676800     79.36\n",
       "2014-02-26  82.92  84.03  82.43  83.81  2623600     81.12\n",
       "2014-02-25  83.80  83.80  81.72  83.08  3579100     80.41"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip 100 lines, then only process the next five\n",
    "pd.read_csv(\"../../data/msft.csv\", skiprows=100, nrows=5, header=0,names=['open','high','low','close','vol','adjclose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing data in Excel Format\n",
    "\n",
    "pandas support reading data in Excel 2003 and newer formats using the pd.read_excel() function or via ExcelFile class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read excel file\n",
    "# only reads first sheet\n",
    "df = pd.read_excel(\"../../data/stocks.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close    Volume  Adj Close\n",
       "0 2014-07-21  94.99  95.00  93.72  93.94  38887700      93.94\n",
       "1 2014-07-18  93.62  94.74  93.02  94.43  49898600      94.43\n",
       "2 2014-07-17  95.03  95.28  92.57  93.09  57152000      93.09\n",
       "3 2014-07-16  96.97  97.10  94.74  94.78  53396300      94.78\n",
       "4 2014-07-15  96.80  96.85  95.03  95.32  45477900      95.32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from the appl worksheet\n",
    "aapl = pd.read_excel(\"../../data/stocks.xlsx\", sheetname='aapl')\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save to excel file in worksheet sheet1\n",
    "df.to_excel(\"../../data/stocks2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write making the worksheet name MSFT\n",
    "df.to_excel(\"../../data/stocks_msft.xlsx\", sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To write more than one DataFrame to a single Excel file and each DataFrame object on a separate worksheet use the ExcelWriter object along with the with keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "with ExcelWriter(\"../../data/all_stocks.xls\") as writer:\n",
    "    aapl.to_excel(writer,sheet_name='AAPL')\n",
    "    df.to_excel(writer,sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to xlsx\n",
    "df.to_excel(\"../../data/msft2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Writing JSON files\n",
    "\n",
    "pandas can read and write data stored on JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Date\":{\"0\":1405900800000,\"1\":1405641600000,\"2\":1405555200000,\"3\":1405468800000,\"4\":1405382400000},\"Open\":{\"0\":83.46,\"1\":83.3,\"2\":84.35,\"3\":83.77,\"4\":84.3},\"High\":{\"0\":83.53,\"1\":83.4,\"2\":84.63,\"3\":84.91,\"4\":84.38},\"Low\":{\"0\":81.81,\"1\":82.52,\"2\":83.33,\"3\":83.66,\"4\":83.2},\"Close\":{\"0\":81.93,\"1\":83.35,\"2\":83.63,\"3\":84.91,\"4\":83.58},\"Volume\":{\"0\":2359300,\"1\":4020800,\"2\":1974000,\"3\":1755600,\"4\":1874700},\"Adj Close\":{\"0\":81.93,\"1\":83.35,\"2\":83.63,\"3\":84.91,\"4\":83.58}}"
     ]
    }
   ],
   "source": [
    "# write the excel data to a JSON file\n",
    "df.head().to_json(\"../../data/stocks.json\")\n",
    "!cat ../../data/stocks.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Adj Close  Close       Date   High    Low   Open   Volume\n",
       "0      81.93  81.93 2014-07-21  83.53  81.81  83.46  2359300\n",
       "1      83.35  83.35 2014-07-18  83.40  82.52  83.30  4020800\n",
       "2      83.63  83.63 2014-07-17  84.63  83.33  84.35  1974000\n",
       "3      84.91  84.91 2014-07-16  84.91  83.66  83.77  1755600\n",
       "4      83.58  83.58 2014-07-15  84.38  83.20  84.30  1874700"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data in from JSON\n",
    "df_from_json = pd.read_json(\"../../data/stocks.json\")\n",
    "df_from_json.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice two slight differences here caused by the reading / writing of data from JSON. First the columns have been reordered alphabetically. Second, the index for DataFram although containing contnet, is sorted as a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading HTML data from the web\n",
    "\n",
    "Underneath the covers pandas makes use of LXML, Html5Lib and BeautifulSoup4 packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnc/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                           Bank Name                City  ST  \\\n",
       "0    The Farmers and Merchants State Bank of Argonia             Argonia  KS   \n",
       "1                                Fayette County Bank          Saint Elmo  IL   \n",
       "2  Guaranty Bank, (d/b/a BestBank in Georgia & Mi...           Milwaukee  WI   \n",
       "3                                     First NBC Bank         New Orleans  LA   \n",
       "4                                      Proficio Bank  Cottonwood Heights  UT   \n",
       "\n",
       "    CERT  \n",
       "0  17719  \n",
       "1   1802  \n",
       "2  30003  \n",
       "3  58302  \n",
       "4  35495  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url to read\n",
    "url = \"http://www.fdic.gov/bank/individual/failed/banklist.html\"\n",
    "# read it\n",
    "banks = pd.read_html(url)\n",
    "# examine a subset of the first table read\n",
    "banks[0][0:5].ix[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\r\n",
      "  <thead>\r\n",
      "    <tr style=\"text-align: right;\">\r\n",
      "      <th></th>\r\n",
      "      <th>Date</th>\r\n",
      "      <th>Open</th>\r\n",
      "      <th>High</th>\r\n",
      "      <th>Low</th>\r\n",
      "      <th>Close</th>\r\n",
      "      <th>Volume</th>\r\n",
      "      <th>Adj Close</th>\r\n",
      "    </tr>\r\n",
      "  </thead>\r\n",
      "  <tbody>\r\n",
      "    <tr>\r\n",
      "      <th>0</th>\r\n",
      "      <td>2014-07-21</td>\r\n",
      "      <td>83.46</td>\r\n",
      "      <td>83.53</td>\r\n",
      "      <td>81.81</td>\r\n",
      "      <td>81.93</td>\r\n",
      "      <td>2359300</td>\r\n",
      "      <td>81.93</td>\r\n",
      "    </tr>\r\n",
      "    <tr>\r\n",
      "      <th>1</th>\r\n",
      "      <td>2014-07-18</td>\r\n",
      "      <td>83.30</td>\r\n"
     ]
    }
   ],
   "source": [
    "# write to html\n",
    "# read the stock data\n",
    "df=pd.read_excel(\"../../data/stocks.xlsx\")\n",
    "# write first 2 rows to HTML\n",
    "df.head(2).to_html(\"../../data/stocks.html\")\n",
    "# check\n",
    "!head -n 28 ../../data/stocks.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Writing HDF5 format files\n",
    "\n",
    "HDF5 is a data model, library and file format to store and manage data. It is commonly used in scientific computing environments. It supports an unlimited variety of data types and is designed for flexible and efficient I/O and for high volume and complex data.\n",
    "\n",
    "HDF5 is portable and extensible allowing applications to evolve in their use of HDF5. HDF5 technology suite includes tools and applications to manage, manipulate, view and analyse data in HDF5 format.\n",
    "\n",
    "HDF5 is:\n",
    "\n",
    "* A Versatile data model that can represent very complex data objects and wide variety of metadata\n",
    "* A completely portable file format with no limit on the number or size of data objects in a collection\n",
    "* A Software library that runs on range of computational platforms from laptops to massively parallel processing systems and implements high level API with C,C++,Fortran and Java interfaces\n",
    "* A rich set of integrated performance features that allows for access time and storage space optimizations.\n",
    "* Tools and applications to manage, manipulate, view and analyze the data in collection\n",
    "\n",
    "HDF5Store is a hierarchical dictionary like object that reads and writes pandas objects to the HDF5 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: ../../data/store.h5\n",
       "/df            frame        (shape->[8,3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed for replication\n",
    "np.random.seed(123456)\n",
    "# create a DataFrame of dates and random numbers in three columns\n",
    "df = pd.DataFrame(np.random.randn(8,3),index=pd.date_range('1/1/2000', periods=8), columns=['A','B','C'])\n",
    "# create HDF5 store\n",
    "store = pd.HDFStore('../../data/store.h5')\n",
    "store['df'] = df # persisting happened here\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   A         B         C\n",
       "2000-01-01  0.469112 -0.282863 -1.509059\n",
       "2000-01-02 -1.135632  1.212112 -0.173215\n",
       "2000-01-03  0.119209 -1.044236 -0.861849\n",
       "2000-01-04 -2.104569 -0.494929  1.071804\n",
       "2000-01-05  0.721555 -0.706771 -1.039575\n",
       "2000-01-06  0.271860 -0.424972  0.567020\n",
       "2000-01-07  0.276232 -1.087401 -0.673690\n",
       "2000-01-08  0.113648 -1.478427  0.524988"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data from HDF5\n",
    "store = pd.HDFStore(\"../../data/store.h5\")\n",
    "df = store['df']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnc/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                   A         B         C\n",
       "2000-01-01  1.000000 -0.282863 -1.509059\n",
       "2000-01-02 -1.135632  1.212112 -0.173215"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this changes the DataFrame, but did not persist\n",
    "df.ix[0].A = 1\n",
    "\n",
    "# to persist the change, assign the dataframe to the\n",
    "# HDF5 store object\n",
    "\n",
    "store['df'] = df\n",
    "# it is now persisted\n",
    "\n",
    "# the following loads the store and\n",
    "# shows the first two rows, demonstrating\n",
    "# the persisting was done\n",
    "pd.HDFStore(\"../../data/store.h5\")['df'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data on the web and in the cloud\n",
    "\n",
    "pandas makes it extremely easy to read data from the web and the cloud. All of the pandas functions we have examined so far can also be given an HTTP URL, FTP address or S3 address instead of a local file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0         time  AirPassengers\n",
       "0           1  1949.000000            112\n",
       "1           2  1949.083333            118\n",
       "2           3  1949.166667            132\n",
       "3           4  1949.250000            129\n",
       "4           5  1949.333333            121"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv directly from Yahoo! Finance from a URL\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/AirPassengers.csv\")\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing from/to SQL databases\n",
    "\n",
    "pandas can read data from any SQL databases that support Python data adapters, that respect the Python DB-API. Reading is performed by using the pandas.io.sql.read_sql() function and writing to SQL databases using the .to_sql() method of DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnc/anaconda/lib/python3.6/site-packages/pandas/core/generic.py:1345: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "# reference SQLITE\n",
    "import sqlite3\n",
    "\n",
    "# read in the stock data from csv\n",
    "msft = pd.read_csv(\"../../data/msft.csv\")\n",
    "msft['Symbol'] = \"MSFT\"\n",
    "aapl = pd.read_csv(\"../../data/aapl.csv\")\n",
    "aapl['Symbol'] = 'AAPL'\n",
    "\n",
    "# create connection\n",
    "connection = sqlite3.connect(\"../../data/stocks.sqlite\")\n",
    "# .to_sql() will create sql to store the DataFrame\n",
    "# in the specified table. if_exists specifies\n",
    "# what to do if the table already exists\n",
    "\n",
    "msft.to_sql(\"STOCK DATA\", connection, if_exists=\"replace\")\n",
    "aapl.to_sql(\"STOCK DATA\", connection, if_exists=\"append\")\n",
    "\n",
    "# commit the sql and close the connection\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Date   Open   High    Low  Close   Volume  Adj Close Symbol\n",
       "index                                                                   \n",
       "0      2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93   MSFT\n",
       "1      2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35   MSFT\n",
       "2      2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63   MSFT\n",
       "3      2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91   MSFT\n",
       "4      2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58   MSFT"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "# connect to the database file\n",
    "connection = sqlite3.connect(\"../../data/stocks.sqlite\")\n",
    "\n",
    "# query all records in STOCK_DATA\n",
    "# returns a DataFrame\n",
    "# index_col specifies which column to make the DataFrame index\n",
    "stocks = pd.io.sql.read_sql(\"SELECT * FROM STOCK_DATA;\", connection, index_col=\"index\")\n",
    "\n",
    "# close the connection\n",
    "connection.close()\n",
    "\n",
    "# report the head of the data received\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Date   Open   High    Low  Close    Volume  Adj Close Symbol\n",
       "index                                                                    \n",
       "1081   2010-05-21  42.22  42.35  40.99  42.00  33610800      36.48   MSFT\n",
       "1097   2010-04-29  46.80  46.95  44.65  45.92  47076200      38.41   MSFT\n",
       "1826   2007-06-15  89.80  92.10  89.55  92.04  30656400      35.87   MSFT\n",
       "3455   2001-03-16  47.00  47.80  46.10  45.33  40806400      17.66   MSFT\n",
       "3712   2000-03-17  49.50  50.00  48.29  50.00  50860500      19.48   MSFT"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the connection\n",
    "connection = sqlite3.connect(\"../../data/stocks.sqlite\")\n",
    "\n",
    "# construct the query string\n",
    "query = \"SELECT * FROM STOCK_DATA WHERE Volume > 29200100 AND Symbol='MSFT';\"\n",
    "\n",
    "# execute and close connection\n",
    "items = pd.io.sql.read_sql(query,connection,index_col='index')\n",
    "connection.close()\n",
    "\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these functions take a connection object, which can be any Python DB-API compatible data adapter, you can more or less work with any supported database data by simply creating an appropriate connection object. The code at pandas level should remain the same for any supported database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from remote data services\n",
    "\n",
    "pandas has direct support for various web-based data source classes in the pandas.io.data namespace. The primary class of interest is pandas.io.data.DataReader, which is implemented to read data from various supported sources and return it to the application directly as DataFrame.\n",
    "\n",
    "Currently, support exists for the following sources via the DataReader class:\n",
    "* Daily historical prices stock from either Yahoo! and Google Finance\n",
    "* Yahoo! Options\n",
    "* Federal Reserve Economic Data Library\n",
    "* Kenneth French's Data Library\n",
    "* The World Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Stock Data from Yahoo! and Google Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close    Volume\n",
       "Date                                                                       \n",
       "2012-01-03  26.549999  26.959999  26.389999  26.770000  22.909807  64731500\n",
       "2012-01-04  26.820000  27.469999  26.780001  27.400000  23.448965  80516100\n",
       "2012-01-05  27.379999  27.730000  27.290001  27.680000  23.688589  56081400\n",
       "2012-01-06  27.530001  28.190001  27.530001  28.110001  24.056585  99455500\n",
       "2012-01-09  28.049999  28.100000  27.719999  27.740000  23.739935  59706800"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "# start and end dates\n",
    "start = datetime.datetime(2012,1,1)\n",
    "end = datetime.datetime(2014,1,27)\n",
    "\n",
    "# read the MSFT stock data from Yahoo!\n",
    "yahoo = web.DataReader('MSFT','yahoo',start,end)\n",
    "yahoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Open   High    Low  Close    Volume\n",
       "Date                                            \n",
       "2016-11-08  60.55  60.78  60.15  60.47  22935355\n",
       "2016-11-09  60.00  60.59  59.20  60.17  49632479\n",
       "2016-11-10  60.48  60.49  57.63  58.70  57822394\n",
       "2016-11-11  58.23  59.12  58.01  59.02  38767843\n",
       "2016-11-14  59.02  59.08  57.28  58.12  41328422"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from google\n",
    "google = web.DataReader('MSFT','google',start,end)\n",
    "google.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              Last     Bid     Ask   Chg\n",
       "Strike Expiry     Type Symbol                                           \n",
       "2.5    2017-11-17 call AAPL171117C00002500  160.00  159.40  161.50  6.75\n",
       "       2017-12-15 call AAPL171215C00002500  154.95  160.15  161.25  0.00\n",
       "       2018-01-19 call AAPL180119C00002500  152.55  153.30  154.05  0.00\n",
       "                  put  AAPL180119P00002500    0.02    0.00    0.02  0.00\n",
       "       2018-04-20 put  AAPL180420P00002500    0.01    0.00    0.01  0.00\n",
       "5.0    2017-11-17 call AAPL171117C00005000  151.80  150.80  151.60  0.00"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify we want all yahoo options data for AAPL\n",
    "# this can take a little time...\n",
    "from pandas_datareader.data import Options\n",
    "aapl = Options('AAPL','yahoo')\n",
    "# read all the data\n",
    "data = aapl.get_all_data()\n",
    "# examine the first six rows and four columns\n",
    "data.iloc[0:6,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            Last   Bid   Ask   Chg\n",
       "Strike Expiry     Type Symbol                                     \n",
       "80.0   2017-11-17 put  AAPL171117P00080000  0.01  0.00  0.05  0.00\n",
       "       2017-12-15 put  AAPL171215P00080000  0.01  0.00  0.01  0.00\n",
       "       2018-01-19 put  AAPL180119P00080000  0.01  0.00  0.02 -0.01\n",
       "       2018-02-16 put  AAPL180216P00080000  0.02  0.00  0.03 -0.01\n",
       "       2018-04-20 put  AAPL180420P00080000  0.10  0.06  0.14  0.00"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all puts at strike price of $80 (first four columns only)\n",
    "data.loc[(80, slice(None),'put'),:].iloc[0:5,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Last, Bid, Ask, Chg]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(80,slice('20150117','20150417'),'put'),:].iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             Last    Bid    Ask  Chg  PctChg\n",
       "Strike Expiry     Type Symbol                                               \n",
       "60.0   2017-11-10 call MSFT171110C00060000  15.05  18.75  18.90  0.0     0.0\n",
       "65.0   2017-11-10 call MSFT171110C00065000  13.85  17.85  19.40  0.0     0.0\n",
       "67.0   2017-11-10 call MSFT171110C00067000  17.25   0.00   0.00  0.0     0.0\n",
       "67.5   2017-11-10 call MSFT171110C00067500   9.05  11.30  11.45  0.0     0.0\n",
       "68.0   2017-11-10 call MSFT171110C00068000   7.80  10.80  10.95  0.0     0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# msft calls expiring on 2015-01-05\n",
    "expiry = datetime.date(2015, 1, 5)\n",
    "msft_calls = Options('MSFT','yahoo').get_call_data(expiry=expiry)\n",
    "msft_calls.iloc[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             Last   Bid    Ask       Chg\n",
       "Strike Expiry     Type Symbol                                           \n",
       "105.0  2017-11-10 call AAPL171110C00105000  69.85   0.0   0.00  0.000000\n",
       "110.0  2017-11-10 call AAPL171110C00110000  62.35   0.0   0.00  0.000000\n",
       "115.0  2017-11-10 call AAPL171110C00115000  59.85   0.0   0.00  0.000000\n",
       "120.0  2017-11-10 call AAPL171110C00120000  51.98  52.2  52.75  8.849998\n",
       "125.0  2017-11-10 call AAPL171110C00125000  32.35  37.2  39.05  0.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# msft calls expiring on 2015-01-17\n",
    "expiry = datetime.date(2015,1,17)\n",
    "aapl_calls = aapl.get_call_data(expiry=expiry)\n",
    "aapl_calls.iloc[0:5,0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from Federal Reserve Economic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  GDP\n",
       "DATE                 \n",
       "2012-01-01  15973.881\n",
       "2012-04-01  16121.851\n",
       "2012-07-01  16227.939\n",
       "2012-10-01  16297.349\n",
       "2013-01-01  16475.440\n",
       "2013-04-01  16541.390\n",
       "2013-07-01  16749.349\n",
       "2013-10-01  16999.888\n",
       "2014-01-01  17031.324"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp = web.DataReader(\"GDP\",\"fred\",datetime.date(2012,1,1),datetime.date(2014,1,27))\n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            A576RC1A027NBEA\n",
       "DATE                       \n",
       "1929-01-01             50.5\n",
       "1930-01-01             46.2\n",
       "1931-01-01             39.2\n",
       "1932-01-01             30.5\n",
       "1933-01-01             29.0\n",
       "...                     ...\n",
       "2009-01-01           6251.4\n",
       "2010-01-01           6377.5\n",
       "2011-01-01           6633.2\n",
       "2012-01-01           6930.3\n",
       "2013-01-01           7114.4\n",
       "\n",
       "[85 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get compensation of employees: Wages and Salaries\n",
    "web.DataReader(\"A576RC1A027NBEA\",\"fred\",datetime.date(1929,1,1),datetime.date(2013,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Kenneth French's Data\n",
    "\n",
    "Kenneth R French is a professor of finance at Tuck School of Business at Dartmouth University. He has created an extensive library of economic data, which is available for download over the Web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0:          Mkt-RF   SMB   HML   WML    RF\n",
       " Date                                   \n",
       " 2010-01   -3.70  2.70 -0.29 -2.23  0.00\n",
       " 2010-02    1.24  0.14  0.10  1.59  0.00\n",
       " 2010-03    6.30 -0.26  3.18  4.26  0.01\n",
       " 2010-04    0.44  3.78  0.77  1.60  0.01\n",
       " 2010-05   -9.52  0.17 -2.54 -0.56  0.01\n",
       " ...         ...   ...   ...   ...   ...\n",
       " 2015-09   -3.91 -0.28 -0.89  3.47  0.00\n",
       " 2015-10    7.30 -2.26  0.21 -2.62  0.00\n",
       " 2015-11   -0.30  1.69 -1.78  2.11  0.00\n",
       " 2015-12   -1.74  0.93 -1.79  3.28  0.01\n",
       " 2016-01   -6.29 -2.10  0.97  0.51  0.01\n",
       " \n",
       " [73 rows x 5 columns], 1:       Mkt-RF    SMB    HML    WML    RF\n",
       " Date                                   \n",
       " 2010   13.94  12.62  -5.14  13.93  0.12\n",
       " 2011   -6.79  -5.41  -4.76   6.30  0.04\n",
       " 2012   16.87  -2.55   6.41   6.35  0.06\n",
       " 2013   28.61  -0.46   5.07  23.68  0.02\n",
       " 2014    3.30  -5.03  -3.88   0.79  0.02\n",
       " 2015   -0.50   3.86 -11.12  17.10  0.02, 'DESCR': 'Global Factors\\n--------------\\n\\nThis file was created using the 201601 Bloomberg database. Missing data are indicated by -99.99. \\n\\n  0 : (73 rows x 5 cols)\\n  1 : Annual Factors: January-December (6 rows x 5 cols)'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from Kenneth French fama global factors data set\n",
    "factors = web.DataReader(\"Global_Factors\",\"famafrench\")\n",
    "factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from the World Bank\n",
    "\n",
    "World Bank datasets are identified using indicators, a text code that represents each dataset. A full list of indicators can be retrieved using the pandas_datareader.get_indicators() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnc/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                               id\n",
       "0              1.0.HCount.1.90usd\n",
       "1               1.0.HCount.2.5usd\n",
       "2            1.0.HCount.Mid10to50\n",
       "3                 1.0.HCount.Ofcl\n",
       "4             1.0.HCount.Poor4uds\n",
       "...                           ...\n",
       "16931    per_sionl.overlap_q1_rur\n",
       "16932    per_sionl.overlap_q1_tot\n",
       "16933    per_sionl.overlap_q1_urb\n",
       "16934     s_policyholders_B2_life\n",
       "16935  s_policyholders_B2_nonlife\n",
       "\n",
       "[16936 rows x 1 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas_datareader import wb\n",
    "all_indicators = wb.get_indicators()\n",
    "# examine some of the indicators\n",
    "all_indicators.ix[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      id                                               name\n",
       "9011         SE.SCH.LIFE  School life expectancy, primary to tertiary, b...\n",
       "10312  SP.DYN.LE00.FE.IN           Life expectancy at birth, female (years)\n",
       "10313     SP.DYN.LE00.IN            Life expectancy at birth, total (years)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search of life expectancy indicators\n",
    "le_indicators = wb.search(\"life expectancy\")\n",
    "le_indicators.iloc[:3,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnc/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                   name  capitalcity iso2c\n",
       "0                 Aruba          NaN    AW\n",
       "1           Afghanistan          NaN    AF\n",
       "2                Africa          NaN    A9\n",
       "3                Angola          NaN    AO\n",
       "4               Albania          NaN    AL\n",
       "5               Andorra          NaN    AD\n",
       "6         Andean Region          NaN    L5\n",
       "7            Arab World          NaN    1A\n",
       "8  United Arab Emirates          NaN    AE\n",
       "9             Argentina          NaN    AR"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get countries and show the 3 digit code and name\n",
    "countries = wb.get_countries()\n",
    "# show a subset of the country data\n",
    "countries.iloc[0:10].ix[:,['name','capitalcity','iso2c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    SP.DYN.LE00.IN\n",
       "country       year                \n",
       "Canada        2014       81.953049\n",
       "              2013       81.772049\n",
       "              2012       81.583512\n",
       "              2011       81.448780\n",
       "              2010       81.197561\n",
       "...                            ...\n",
       "United States 1984       74.563415\n",
       "              1983       74.463415\n",
       "              1982       74.360976\n",
       "              1981       74.009756\n",
       "              1980       73.609756\n",
       "\n",
       "[105 rows x 1 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get life expectancy at birth for all countries from 1980 to 2014\n",
    "le_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\", start='1980',end='2014')\n",
    "le_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Canada', 'Mexico', 'United States'], dtype='object', name='country')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only US, CAN and MEX are returned by default\n",
    "le_data_all.index.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cnc/anaconda/lib/python3.6/site-packages/pandas_datareader/wb.py:145: UserWarning: Non-standard ISO country codes: 1A, 1W, 4E, 6D, 6F, 6L, 6N, 6X, 7E, 8S, A4, A5, A9, B1, B2, B3, B4, B6, B7, B8, C4, C5, C6, C7, C8, C9, D2, D3, D4, D5, D6, D7, D8, D9, EU, F1, F6, JG, L4, L5, L6, L7, M1, M2, N6, O6, OE, R6, S1, S2, S3, S4, T2, T3, T4, T5, T6, T7, V1, V2, V3, V4, XC, XD, XE, XF, XG, XH, XI, XJ, XK, XL, XM, XN, XO, XP, XQ, XT, XU, XY, Z4, Z7, ZB, ZF, ZG, ZJ, ZQ, ZT\n",
      "  'country codes: %s' % tmp, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               SP.DYN.LE00.IN\n",
       "country  year                \n",
       "Aruba    2012       75.183195\n",
       "         2011       75.047659\n",
       "         2010       74.910634\n",
       "         2009       74.771146\n",
       "         2008       74.627683\n",
       "...                       ...\n",
       "Zimbabwe 1984       60.932756\n",
       "         1983       60.711585\n",
       "         1982       60.350878\n",
       "         1981       59.886049\n",
       "         1980       59.355561\n",
       "\n",
       "[8679 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieve life expectancy at birth for all countries\n",
    "# from 1980 to 2014\n",
    "le_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\",country=countries['iso2c'],start='1980',end='2012')\n",
    "le_data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do some interesting things with this data. The example we will look at, determines which country has the lowest life expectancy for each year. To do this, we first need to pivot this data, so that the index is the country name and the year is the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   SP.DYN.LE00.IN                      \n",
       "year                         1980       1981       1982\n",
       "country                                                \n",
       "Afghanistan             41.875244  42.533610  43.235902\n",
       "Albania                 70.235976  70.454463  70.685122\n",
       "Algeria                 58.164024  59.486756  60.786341\n",
       "American Samoa                NaN        NaN        NaN\n",
       "Andorra                       NaN        NaN        NaN\n",
       "...                           ...        ...        ...\n",
       "West Bank and Gaza            NaN        NaN        NaN\n",
       "World                   62.865800  63.200694  63.519298\n",
       "Yemen, Rep.             50.559537  51.541341  52.492707\n",
       "Zambia                  51.248293  50.943171  50.514366\n",
       "Zimbabwe                59.355561  59.886049  60.350878\n",
       "\n",
       "[263 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# le_data_all.pivot(index='country',columns='year')\n",
    "le_data = le_data_all.reset_index().pivot(index='country',columns='year')\n",
    "# examine pivoted data\n",
    "le_data.iloc[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                year\n",
       "SP.DYN.LE00.IN  1980                    Cambodia\n",
       "                1981                    Cambodia\n",
       "                1982                 Timor-Leste\n",
       "                1983                 South Sudan\n",
       "                1984                 South Sudan\n",
       "                                  ...           \n",
       "                2008    Central African Republic\n",
       "                2009    Central African Republic\n",
       "                2010    Central African Republic\n",
       "                2011    Central African Republic\n",
       "                2012    Central African Republic\n",
       "Length: 33, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask what is the name of the country for each year\n",
    "# with the least life expectancy\n",
    "country_with_least_expectancy = le_data.idxmin(axis=0)\n",
    "country_with_least_expectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                year\n",
       "SP.DYN.LE00.IN  1980    27.738976\n",
       "                1981    33.449927\n",
       "                1982    38.186220\n",
       "                1983    39.666488\n",
       "                1984    39.999537\n",
       "                          ...    \n",
       "                2008    46.163171\n",
       "                2009    46.834927\n",
       "                2010    47.532707\n",
       "                2011    48.256976\n",
       "                2012    49.012146\n",
       "Length: 33, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and what is the minimum life expectancy for each year\n",
    "expectancy_for_least_country = le_data.min(axis=0)\n",
    "expectancy_for_least_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       Country  Expectancy\n",
       "year                                      \n",
       "1980                  Cambodia   27.738976\n",
       "1981                  Cambodia   33.449927\n",
       "1982               Timor-Leste   38.186220\n",
       "1983               South Sudan   39.666488\n",
       "1984               South Sudan   39.999537\n",
       "...                        ...         ...\n",
       "2008  Central African Republic   46.163171\n",
       "2009  Central African Republic   46.834927\n",
       "2010  Central African Republic   47.532707\n",
       "2011  Central African Republic   48.256976\n",
       "2012  Central African Republic   49.012146\n",
       "\n",
       "[33 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this merges the two frames together and gives us\n",
    "# year, country and expectancy where the minimum exists\n",
    "least = pd.DataFrame(data={'Country':country_with_least_expectancy.values,\n",
    "                          'Expectancy':expectancy_for_least_country.values},\n",
    "                    index= country_with_least_expectancy.index.levels[1])\n",
    "least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
