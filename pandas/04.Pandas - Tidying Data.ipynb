{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidying Data\n",
    "\n",
    "Tidying of data is required for many reasons including these:\n",
    "\n",
    "* The names of the variables are different from what you require\n",
    "* Missing data\n",
    "* Values are not in units that you require\n",
    "* Period of sampling of records is not what you need\n",
    "* Variables are categorical and you neeed quantitative values\n",
    "* There is noise in the data\n",
    "* Information is of an incorrect type\n",
    "* Data is organized around incorrect axes\n",
    "* Data is at the wrong level of normalization\n",
    "* Data is duplicated\n",
    "\n",
    "Moving away from a list of problems with data that needs to be addressed, there are several characterisitics of data that can be considered good, tidy and ready for analysis which are as follows:\n",
    "\n",
    "* Each variable is in one column\n",
    "* Each observation of the variable is in a different row\n",
    "* There should be one table for each kind of variable\n",
    "* If multiple tables they should be relatable\n",
    "* Qualitative and categorical variables have mappings to values useful for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas, numpy and datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# set some pandas options for controlling output\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns',10)\n",
    "pd.set_option('display.max_rows',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Missing Data\n",
    "\n",
    "Data is \"missing\" in pandas when it has a value of NaN (also seen as np.nan - the form from NumPy). The NaN value represents that in a particular Series that there is not a value specified for the particular index level.\n",
    "\n",
    "In pandas, there are a number of reasons why a value can be NaN:\n",
    "\n",
    "* Join of two sets of data does not have matched values\n",
    "* Data that you retrieved from an external source is incomplete\n",
    "* NaN is not known at a give point in time and will be filled in later\n",
    "* There is a data collection error retrieving a value, but the event must still be recorded in the index\n",
    "* Reindexing of data has resulted in an index that does not have a value\n",
    "* Shape of a data has changed, there are new additional rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3\n",
       "a     0     1     2\n",
       "b     3     4     5\n",
       "c     6     7     8\n",
       "d     9    10    11\n",
       "e    12    13    14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame with 5 rows and 3 columns\n",
    "df = pd.DataFrame(np.arange(0,15).reshape(5,3),index=['a','b','c','d','e'], columns=['col1','col2','col3'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   NaN   NaN   NaN   NaN NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add some columns and rows to the DataFrame\n",
    "# column c4 with NaN values\n",
    "df['c4'] = np.nan\n",
    "# row 'f' with 15 through 18\n",
    "df.loc['f'] = np.arange(15,19)\n",
    "# row 'g' with all NaN\n",
    "df.loc['g'] = np.nan\n",
    "# column c5 with NaN's\n",
    "df['c5'] = np.nan\n",
    "# change value in col 'c4' row 'a'\n",
    "df['c4']['a']=20\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame object exhibits the following characteristics that will support most of the examples that follows:\n",
    "\n",
    "* One row consisting only of NaN values\n",
    "* One column is consisting only of NaN values\n",
    "* Several rows and columns consisting of both numeric and NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining NaN values in Series and DataFrame objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    col1   col2   col3     c4    c5\n",
       "a  False  False  False  False  True\n",
       "b  False  False  False   True  True\n",
       "c  False  False  False   True  True\n",
       "d  False  False  False   True  True\n",
       "e  False  False  False   True  True\n",
       "f  False  False  False  False  True\n",
       "g   True   True   True   True  True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which items are NaN?\n",
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    1\n",
       "col2    1\n",
       "col3    1\n",
       "c4      5\n",
       "c5      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of NaN values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total count of NaN values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    6\n",
       "col2    6\n",
       "col3    6\n",
       "c4      2\n",
       "c5      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of non-NaN values in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and can used for counting NaN values\n",
    "(len(df)-df.count()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    col1   col2   col3     c4     c5\n",
       "a   True   True   True   True  False\n",
       "b   True   True   True  False  False\n",
       "c   True   True   True  False  False\n",
       "d   True   True   True  False  False\n",
       "e   True   True   True  False  False\n",
       "f   True   True   True   True  False\n",
       "g  False  False  False  False  False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which items are not null\n",
    "df.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting out or dropping missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the non-NaN items in column c4\n",
    "df.c4[df.c4.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "f    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .dropna will also return non NaN values\n",
    "# this gets all non NaN items in column c4\n",
    "df.c4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropna returns as copy with the values dropped\n",
    "# the source DataFrame / column is not changed\n",
    "df.c4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applied to a DataFrame object, dropna() will drop all rows froms a DataFrame object that have atleast one NaN value. If you want to drop only rows where all values are NaN, you can use the how=\"all\" parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [col1, col2, col3, c4, c5]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on a dataframe this will drop entire rows\n",
    "# where there is atleast one NaN\n",
    "# in this case, all the rows\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using how='all', only rows that have all values\n",
    "# as NaN will be dropped\n",
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3    c4\n",
       "a   0.0   1.0   2.0  20.0\n",
       "b   3.0   4.0   5.0   NaN\n",
       "c   6.0   7.0   8.0   NaN\n",
       "d   9.0  10.0  11.0   NaN\n",
       "e  12.0  13.0  14.0   NaN\n",
       "f  15.0  16.0  17.0  18.0\n",
       "g   NaN   NaN   NaN   NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flip to drop columns instead of rows\n",
    "df.dropna(how='all',axis=1) # c5 column will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0   NaN NaN\n",
       "c   6.0   7.0   8.0   NaN NaN\n",
       "d   9.0  10.0  11.0   NaN NaN\n",
       "e  12.0  13.0  14.0   NaN NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   0.0   NaN   0.0   NaN NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy of df\n",
    "df2 = df.copy()\n",
    "# replace two NaN cells with values\n",
    "df2.loc['g'].col1=0\n",
    "df2.loc['g'].col3=0\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col3\n",
       "a   0.0   2.0\n",
       "b   3.0   5.0\n",
       "c   6.0   8.0\n",
       "d   9.0  11.0\n",
       "e  12.0  14.0\n",
       "f  15.0  17.0\n",
       "g   0.0   0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now drop columns with any NaN values\n",
    "df2.dropna(how='any',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3\n",
       "a   0.0   1.0   2.0\n",
       "b   3.0   4.0   5.0\n",
       "c   6.0   7.0   8.0\n",
       "d   9.0  10.0  11.0\n",
       "e  12.0  13.0  14.0\n",
       "f  15.0  16.0  17.0\n",
       "g   NaN   NaN   NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only drop columns with at least 5 NaN values\n",
    "df.dropna(thresh=5,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the .dropna() method returns a copy of the DataFrame object, and the data is dropped from that copy. If you want to drop the data in the actual DataFrame, use the inplace=True parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How pandas handles NaN values in mathematical operations\n",
    "\n",
    "The NaN values are handled differently in pandas than in NumPy. NumPy functions when encountering a NaN value, will return NaN. pandas functions will typically ignore the NaN values and continue processing the function as though the values were not part of the Series object.\n",
    "\n",
    "More specifically the way that pandas handles NaN values is as follows:\n",
    "* Summing of data treats NaN as 0\n",
    "* If all values are NaN, the result is NaN\n",
    "* Methods like .cumsum() and .cumprod() ignore NaN values but preserve them in resulting arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, 2.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a NumPy array with one NaN value\n",
    "a = np.array([1,2,np.nan,3])\n",
    "# create a Series from the array\n",
    "s = pd.Series(a)\n",
    "# the mean of each is different\n",
    "a.mean(), s.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate sum,mean and cumsum handling of NaN\n",
    "# get one column\n",
    "s = df.c4\n",
    "s.sum()   # NaN values treated a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean() # NaN treated as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    38.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as 0 in the cumsum but NaN values preserved in result series\n",
    "s.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    21.0\n",
       "b     NaN\n",
       "c     NaN\n",
       "d     NaN\n",
       "e     NaN\n",
       "f    19.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in arithmetic, a NaN value will result in NaN\n",
    "df.c4 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing data\n",
    "\n",
    "If you prefer to replace the NaN values with a specific value, instead of having them propagated or flat out ignored, you can use the .fillna() method. The following code fills the NaN values with 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3    c4   c5\n",
       "a   0.0   1.0   2.0  20.0  0.0\n",
       "b   3.0   4.0   5.0   0.0  0.0\n",
       "c   6.0   7.0   8.0   0.0  0.0\n",
       "d   9.0  10.0  11.0   0.0  0.0\n",
       "e  12.0  13.0  14.0   0.0  0.0\n",
       "f  15.0  16.0  17.0  18.0  0.0\n",
       "g   0.0   0.0   0.0   0.0  0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return a new DataFrame with NaN values filled with 0\n",
    "filled = df.fillna(0)\n",
    "filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    6.428571\n",
       "col2    7.285714\n",
       "col3    8.142857\n",
       "c4      5.428571\n",
       "c5      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having replaced NaN with 0 can make\n",
    "# operations such as mean have different results\n",
    "filled.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to limit the number of times that the data will be filled using the limit parameter. Each time the NaN values are identified, pandas will fill the NaN values with the previous value up to the limit times in each group of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3    c4   c5\n",
       "a   0.0   1.0   2.0  20.0  0.0\n",
       "b   3.0   4.0   5.0   0.0  0.0\n",
       "c   6.0   7.0   8.0   0.0  NaN\n",
       "d   9.0  10.0  11.0   NaN  NaN\n",
       "e  12.0  13.0  14.0   NaN  NaN\n",
       "f  15.0  16.0  17.0  18.0  NaN\n",
       "g   0.0   0.0   0.0   NaN  NaN"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only fills the first two NaN values in each row with 0\n",
    "df.fillna(0,limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward and Backward Filling of Missing Values\n",
    "\n",
    "Gaps in data can be filled by propagating the non-NaN values forward or backward along a Series. To demonstrate this, the following example will \"fill forward\" the c4 column of DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    20.0\n",
       "c    20.0\n",
       "d    20.0\n",
       "e    20.0\n",
       "f    18.0\n",
       "g    18.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the c4 column and fill NaNs forward\n",
    "df.c4.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    20.0\n",
       "b    18.0\n",
       "c    18.0\n",
       "d    18.0\n",
       "e    18.0\n",
       "f    18.0\n",
       "g     NaN\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform a backword fill\n",
    "df.c4.fillna(method=\"bfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the convenient functions pd.ffill() or pd.bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Using index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    100\n",
       "e    101\n",
       "g    102\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new series of values to be\n",
    "# used to fill NaN values where the index label matches\n",
    "fill_values = pd.Series([100,101,102], index=['a','e','g'])\n",
    "fill_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a     20.0\n",
       "b      NaN\n",
       "c      NaN\n",
       "d      NaN\n",
       "e    101.0\n",
       "f     18.0\n",
       "g    102.0\n",
       "Name: c4, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using c4, fill using fill_values\n",
    "# a, e and g will be filled with matching values\n",
    "df.c4.fillna(fill_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   col1  col2  col3    c4  c5\n",
       "a   0.0   1.0   2.0  20.0 NaN\n",
       "b   3.0   4.0   5.0  19.0 NaN\n",
       "c   6.0   7.0   8.0  19.0 NaN\n",
       "d   9.0  10.0  11.0  19.0 NaN\n",
       "e  12.0  13.0  14.0  19.0 NaN\n",
       "f  15.0  16.0  17.0  18.0 NaN\n",
       "g   7.5   8.5   9.5  19.0 NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill NaN values in each column with the\n",
    "# mean of the values in that column\n",
    "df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation of missing values\n",
    "\n",
    "Both DataFrame and Series have an .interpolate() method that will, by default, perform a linear interpolation of missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.00\n",
       "1    1.25\n",
       "2    1.50\n",
       "3    1.75\n",
       "4    2.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate the NaN values from 1 through 2\n",
    "s = pd.Series([1,np.nan,np.nan,np.nan,2])\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of interpolation is calculated by taking the first value before and after any sequence of NaN values and then incrementally adding that value from the start and substituting NaN values. In this case, 2.0 and 1.0 are the surrounding values resulting in (2.0-1.0)/(5-1)=0.25 which is then added incrementally through all the NaN values.\n",
    "\n",
    "The interpolation method also has the ability to specify a specific method of interpolation, one of the common methods is to use time-based interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    NaN\n",
       "2014-04-01    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a time series, but missing one date in the Series\n",
    "ts = pd.Series([1,np.nan,3],index=[datetime.datetime(2014,1,1),datetime.datetime(2014,2,1),datetime.datetime(2014,4,1)])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.0\n",
       "2014-02-01    2.0\n",
       "2014-04-01    3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing to note is that the series is missing an entry for 2014-03-01. If we were expecting to interpolate daily values, there would be two values calculated one for 2014-02-01 and another for 2014-03-01 resulting in one more value in the numerator of the interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01    1.000000\n",
       "2014-02-01    1.688889\n",
       "2014-04-01    3.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this accounts for the fact that we dont have\n",
    "# an entry for 2014-03-01\n",
    "ts.interpolate(method=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolation can also be specified to calculate values relative to the index values when using numeric index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       NaN\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a series to demonstrate index label based interpolation\n",
    "s = pd.Series([0,np.nan,100], index=[0,1,10])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      50.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear interpolate\n",
    "s.interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1      10.0\n",
       "10    100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpolate based upon the values in the index\n",
    "s.interpolate(method=\"values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the value calculated for NaN is interpolated using relative positioning based upon the labels in the index. The NaN value has a label of 1, which is one tenth of the way between 0 and 10 so the interpolated value will be\n",
    "0 + (100-0)/10 or 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Duplicate Data\n",
    "\n",
    "Often it is considered best to erron the side of having duplicates instead of missing data, especially if the data is considered to be idempotent. However duplicate data can increase the size of the dataset and if it is not idempotent, then it would not be appropriate to process the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "1  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "4  y  3\n",
       "5  y  4\n",
       "6  y  4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a DataFrame with lots of duplicate data\n",
    "data = pd.DataFrame({'a':['x'] * 3 + ['y'] * 4,'b':[1,1,2,3,3,4,4]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4     True\n",
       "5    False\n",
       "6     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reports which rows are duplicates based upon\n",
    "# if the data in all columns was seen before\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  x  1\n",
       "2  x  2\n",
       "3  y  3\n",
       "5  y  4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows retaining first row of the duplicates\n",
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default operation is to keep the first row of the duplicates. If you want to keep the last row of duplicates, you can use the take_last=True parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "1  x  1\n",
       "2  x  2\n",
       "4  y  3\n",
       "6  y  4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate rows only keeping the first instance of any data\n",
    "data.drop_duplicates(keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column c with values 0..6\n",
    "# this makes .duplicated() report no duplicate rows\n",
    "data['c'] = range(7)\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b  c\n",
       "0  x  1  0\n",
       "2  x  2  2\n",
       "3  y  3  3\n",
       "5  y  4  5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but if we specify duplicates to be dropped in columns a & b\n",
    "# they will be dropped\n",
    "data.drop_duplicates(['a','b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data\n",
    "\n",
    "Transformation is required for following reasons:\n",
    "* Values are not in the correct units\n",
    "* Values are qualitative and need to be converted to appropriate numeric values\n",
    "* Extraneous data that either wastes memory and processing time or can affect results simply by being included\n",
    "\n",
    "To address these situations we can take one or more of the following actions:\n",
    "* Map values to other values using a table lookup process\n",
    "* Explicitly replace certain values with other values\n",
    "* Apply methods to transform the values based on an algorithm\n",
    "* Simple remove extraneous columns and rows\n",
    "\n",
    "### Mapping\n",
    "\n",
    "pandas provides a generic ability to map values using a lookup table using the .map() method. This method performs the mapping by matching the values of the outer Series with the index labels of the inner Series returning a new Series with the index labels of the outer Series but the values from the inner Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      1\n",
       "three    3\n",
       "two      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create two Series objects to demonstrate mapping\n",
    "x = pd.Series({\"one\":1,\"two\":2,\"three\":3})\n",
    "y = pd.Series({1:\"a\",2:\"b\",3:\"c\"})\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    a\n",
       "2    b\n",
       "3    c\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one      a\n",
       "three    c\n",
       "two      b\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map values in x to values in y\n",
    "x.map(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "one        a\n",
       "three    NaN\n",
       "two        b\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# three in x will not align / map to a value in y\n",
    "x = pd.Series({\"one\":1,\"two\":2,\"three\":3})\n",
    "y = pd.Series({1:\"a\",2:\"b\"})\n",
    "x.map(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    3.0\n",
       "4    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a Series to demonstrate replace\n",
    "s = pd.Series([0.,1.,2.,3.,4.])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    5.0\n",
       "3    3.0\n",
       "4    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all items with index label 2 with value 5\n",
    "s.replace(2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.0\n",
       "1    3.0\n",
       "2    2.0\n",
       "3    1.0\n",
       "4    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace all items with new values\n",
    "s.replace([0,1,2,3,4],[4,3,2,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     10.0\n",
       "1    100.0\n",
       "2      2.0\n",
       "3      3.0\n",
       "4      4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace using entries in a dictionary\n",
    "s.replace({0:10,1:100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using .replace() on a DataFrame, it is possible to specify different replacement values for each column. This is performed by passing a Python dictionary to the .replace() method, where the keys of the dictionary represent the names of the columns where replacement is to occur and the values of the dictionary are values that you want to replace. The second parameter to the method is the value that will be replaced where any matches are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a  b\n",
       "0  0  5\n",
       "1  1  6\n",
       "2  2  7\n",
       "3  3  8\n",
       "4  4  9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame with two columns\n",
    "df = pd.DataFrame({'a':[0,1,2,3,4],'b':[5,6,7,8,9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     a    b\n",
       "0    0    5\n",
       "1  100    6\n",
       "2    2    7\n",
       "3    3  100\n",
       "4    4    9"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify different replacement values for each column\n",
    "df.replace({'a':1,'b':8}, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing specific values in each of the columns is very convenient, as it provides a shorthand for what otherwise would require coding a loop through all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1     1.0\n",
       "2     2.0\n",
       "3     3.0\n",
       "4     4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate replacement with pad method\n",
    "# set first item to 10, to have a distinct replacement value\n",
    "s[0] = 10\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "1    10.0\n",
       "2    10.0\n",
       "3    10.0\n",
       "4     4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace items with index label 1,2,3 using fill from the\n",
    "# most recent value prior to the specified labels (10)\n",
    "s.replace([1,2,3],method='pad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Functions to Transform Data\n",
    "\n",
    "pandas provides the ability to apply functions to individual items, entire columns, entire rows providing incredible flexibility in transformation.\n",
    "\n",
    "Functions can be applied using the conveniently named .apply() method, which given a Python function, will iteratively call the function passing in each value from a Series, or each Series representing a DataFrame column, or a list of values representing each row in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    2\n",
       "2    4\n",
       "3    6\n",
       "4    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a function to every item of a series\n",
    "s = pd.Series(np.arange(0,5))\n",
    "s.apply(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c\n",
       "0  0   1   2\n",
       "1  3   4   5\n",
       "2  6   7   8\n",
       "3  9  10  11"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a sum on each column\n",
    "df = pd.DataFrame(np.arange(12).reshape(4,3),columns=['a','b','c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    18\n",
       "b    22\n",
       "c    26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cumulative sum of items in each column\n",
    "df.apply(lambda col: col.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3\n",
       "1    12\n",
       "2    21\n",
       "3    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the sum of items in each row\n",
    "df.apply(lambda row: row.sum(),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common practice is to take result of an apply operation and add it as a new column of the DataFrame. This is convenient as you can add into the DataFrame the result of one or more successive calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c  interim\n",
       "0  0   1   2        0\n",
       "1  3   4   5       12\n",
       "2  6   7   8       42\n",
       "3  9  10  11       90"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column 'interim' with a * b\n",
    "df['interim'] = df.apply(lambda r: r.a * r.b,axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   a   b   c  interim  result\n",
       "0  0   1   2        0       2\n",
       "1  3   4   5       12      17\n",
       "2  6   7   8       42      50\n",
       "3  9  10  11       90     101"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and now a 'result' column with 'interim' + 'c'\n",
    "df['result'] = df.apply(lambda r: r.interim + r.c, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    a   b   c  interim  result\n",
       "0   3   1   2        0       2\n",
       "1  12   4   5       12      17\n",
       "2  21   7   8       42      50\n",
       "3  30  10  11       90     101"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace column a with the sum of columns a,b and c\n",
    "df.a = df.a + df.b + df.c\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important point to note is that pandas DataFrame is not a spreadsheet where cells are assigned formulas and can be recalculated when cells that are referenced by the formula change. If you desire this to happen, you will need to execute the formulas whenever the dependent data changes. On the flip side, this is more efficient than with spreadsheets as every little change does not cause a cascade of operations to occur.\n",
    "\n",
    "The .apply() method will always apply to the provided function to all of the items or rows or columns. If you want to apply the function to a subset of these, then first perform a Boolean selection to filter all the items you do not want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    0   1     2   3   4\n",
       "0   0   1   2.0   3   4\n",
       "1   5   6   NaN   8   9\n",
       "2  10  11  12.0  13  14"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a 3 X 5 dataframe\n",
    "df = pd.DataFrame(np.arange(0,15).reshape(3,5))\n",
    "df.loc[1,2]= np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10.0\n",
       "2    60.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstrate applying a function to only rows having\n",
    "# a count of 0 NaN values\n",
    "df.dropna().apply(lambda x:x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .apply() method was always passed an entire row or column. If you desire to apply a function to every individual item in the DataFrame one by one then .applymap() is the method to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       0      1      2      3      4\n",
       "0   0.00   1.00   2.00   3.00   4.00\n",
       "1   5.00   6.00    nan   8.00   9.00\n",
       "2  10.00  11.00  12.00  13.00  14.00"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use applymap to format all items of the DataFrame\n",
    "df.applymap(lambda x: '%.2f' % x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
